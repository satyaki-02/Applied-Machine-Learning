{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bPbKpYd7umIz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\j25sr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\j25sr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\j25sr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import  accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/04 21:42:12 INFO mlflow.tracking.fluent: Experiment with name 'SMSSpamDetectionModels' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/j25sr/OneDrive/Desktop/Sem%204/AML/Applied-Machine-Learning/Assignment_2/mlruns/313760295266013132', creation_time=1741104732203, experiment_id='313760295266013132', last_update_time=1741104732203, lifecycle_stage='active', name='SMSSpamDetectionModels', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"SMSSpamDetectionModels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "T4_KJatGwa70"
   },
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    msg_train = pd.read_csv(file_path+ 'msg_train.csv').squeeze()\n",
    "    msg_val = pd.read_csv(file_path+ 'msg_val.csv').squeeze()\n",
    "    msg_test = pd.read_csv(file_path+ 'msg_test.csv').squeeze()\n",
    "    label_train = pd.read_csv(file_path+ 'label_train.csv').squeeze()\n",
    "    label_val = pd.read_csv(file_path+ 'label_val.csv').squeeze()\n",
    "    label_test = pd.read_csv(file_path+ 'label_test.csv').squeeze()\n",
    "    return msg_train, msg_val, msg_test, label_train, label_val, label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/j25sr/OneDrive/Desktop/AML 1/split_dataset/split_dataset\"\n",
    "msg_train, msg_val, msg_test, label_train, label_val, label_test = load_data(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_logistic = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=lambda x: x, preprocessor=None, lowercase=False)),  # Directly handle tokenized data\n",
    "    ('classifier', LogisticRegression(solver='liblinear')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/04 21:47:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'LogisticRegressionModel' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'LogisticRegressionModel'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model registered as 'LogisticRegressionModel' with version: 2\n",
      "\n",
      "Best Parameters (Logistic Regression): (True, 10, 'l1')\n",
      "Final Metrics (Logistic Regression):\n",
      "Accuracy: 98.48%\n",
      "Precision: 97.14%\n",
      "Recall: 91.28%\n",
      "F1-score: 94.12%\n",
      "AUCPR: 98.58%\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "def param_search_logistic(msg_train, label_train, msg_val, label_val, pipeline_logistic):\n",
    "    param_grid = {\n",
    "        'tfidf__use_idf': [True, False],\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__penalty': ['l1', 'l2']\n",
    "    }\n",
    "\n",
    "    param_combinations = list(product(*param_grid.values()))\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_metrics = {}\n",
    "\n",
    "    for params in param_combinations:\n",
    "        try:\n",
    "            # Ensure 'l1' penalty is used only with solvers that support it\n",
    "            penalty = params[2]\n",
    "            solver = 'liblinear' if penalty == 'l1' else 'lbfgs'\n",
    "\n",
    "            pipeline_logistic.set_params(\n",
    "                tfidf__use_idf=params[0],\n",
    "                classifier__C=params[1],\n",
    "                classifier__penalty=penalty,\n",
    "                classifier__solver=solver  # Explicitly set compatible solver\n",
    "            )\n",
    "            \n",
    "            pipeline_logistic.fit(msg_train, label_train)\n",
    "            val_predictions = pipeline_logistic.predict(msg_val)\n",
    "            val_probabilities = pipeline_logistic.predict_proba(msg_val)[:, 1]\n",
    "\n",
    "            # Compute evaluation metrics\n",
    "            val_accuracy = accuracy_score(label_val, val_predictions)\n",
    "            val_precision = precision_score(label_val, val_predictions, pos_label='spam', zero_division=0)\n",
    "            val_recall = recall_score(label_val, val_predictions, pos_label='spam', zero_division=0)\n",
    "            val_f1 = f1_score(label_val, val_predictions, pos_label='spam', zero_division=0)\n",
    "            val_aucpr = average_precision_score((label_val == 'spam').astype(int), val_probabilities)\n",
    "\n",
    "            # Track best model\n",
    "            if val_f1 > best_score:\n",
    "                best_score = val_f1\n",
    "                best_params = params\n",
    "                best_model = pipeline_logistic\n",
    "                best_metrics = {\n",
    "                    \"Accuracy\": val_accuracy,\n",
    "                    \"Precision\": val_precision,\n",
    "                    \"Recall\": val_recall,\n",
    "                    \"F1-score\": val_f1,\n",
    "                    \"AUCPR\": val_aucpr\n",
    "                }\n",
    "        \n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping params {params} due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Log only the best model\n",
    "    if best_model:\n",
    "        with mlflow.start_run(run_name=\"Best_Logistic_Regression\"):\n",
    "            mlflow.log_params({\"use_idf\": best_params[0], \"C\": best_params[1], \"penalty\": best_params[2]})\n",
    "            mlflow.log_metrics(best_metrics)\n",
    "\n",
    "            # Log best model and get ModelInfo object\n",
    "            model_info = mlflow.sklearn.log_model(best_model, \"logistic_regression_model\")\n",
    "\n",
    "            # Extract model URI and register it\n",
    "            model_uri = model_info.model_uri\n",
    "            model_version = mlflow.register_model(model_uri, \"LogisticRegressionModel\")\n",
    "\n",
    "            print(f\"Model registered as 'LogisticRegressionModel' with version: {model_version.version}\")\n",
    "    \n",
    "    return best_params, best_metrics\n",
    "\n",
    "# Run the search\n",
    "best_params_logistic, best_metrics_logistic = param_search_logistic(msg_train, label_train, msg_val, label_val, pipeline_logistic)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nBest Parameters (Logistic Regression):\", best_params_logistic)\n",
    "print(f\"Final Metrics (Logistic Regression):\")\n",
    "for metric, value in best_metrics_logistic.items():\n",
    "    print(f\"{metric}: {value * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_svm = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=lambda x: x, preprocessor=None, lowercase=False)),\n",
    "    ('classifier', SVC()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/04 21:47:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'SVMModel' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model registered as 'SVMModel' with version: 2\n",
      "\n",
      "Best Parameters (SVM): (True, 10, 'rbf')\n",
      "Final Metrics (SVM):\n",
      "Accuracy: 98.57%\n",
      "Precision: 98.54%\n",
      "Recall: 90.60%\n",
      "F1-score: 94.41%\n",
      "AUCPR: 98.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'SVMModel'.\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "def param_search_svm(msg_train, label_train, msg_val, label_val, pipeline_svm):\n",
    "    param_grid = {\n",
    "        'tfidf__use_idf': [True, False],\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__kernel': ['linear', 'rbf']\n",
    "    }\n",
    "\n",
    "    param_combinations = list(product(*param_grid.values()))\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_metrics = {}\n",
    "\n",
    "    for params in param_combinations:\n",
    "        try:\n",
    "            # Set parameters for the pipeline\n",
    "            pipeline_svm.set_params(\n",
    "                tfidf__use_idf=params[0],\n",
    "                classifier__C=params[1],\n",
    "                classifier__kernel=params[2]\n",
    "            )\n",
    "            \n",
    "            pipeline_svm.fit(msg_train, label_train)\n",
    "            val_predictions = pipeline_svm.predict(msg_val)\n",
    "            val_probabilities = pipeline_svm.decision_function(msg_val)  # SVM uses decision_function\n",
    "\n",
    "            # Compute evaluation metrics\n",
    "            val_accuracy = accuracy_score(label_val, val_predictions)\n",
    "            val_precision = precision_score(label_val, val_predictions, pos_label='spam', zero_division=0)\n",
    "            val_recall = recall_score(label_val, val_predictions, pos_label='spam', zero_division=0)\n",
    "            val_f1 = f1_score(label_val, val_predictions, pos_label='spam', zero_division=0)\n",
    "            val_aucpr = average_precision_score((label_val == 'spam').astype(int), val_probabilities)\n",
    "\n",
    "            # Track best model\n",
    "            if val_f1 > best_score:\n",
    "                best_score = val_f1\n",
    "                best_params = params\n",
    "                best_model = pipeline_svm\n",
    "                best_metrics = {\n",
    "                    \"Accuracy\": val_accuracy,\n",
    "                    \"Precision\": val_precision,\n",
    "                    \"Recall\": val_recall,\n",
    "                    \"F1-score\": val_f1,\n",
    "                    \"AUCPR\": val_aucpr\n",
    "                }\n",
    "        \n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping params {params} due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Log only the best model\n",
    "    if best_model:\n",
    "        with mlflow.start_run(run_name=\"Best_SVM\"):\n",
    "            mlflow.log_params({\"use_idf\": best_params[0], \"C\": best_params[1], \"kernel\": best_params[2]})\n",
    "            mlflow.log_metrics(best_metrics)\n",
    "\n",
    "            # Log best model and get ModelInfo object\n",
    "            model_info = mlflow.sklearn.log_model(best_model, \"svm_model\")\n",
    "\n",
    "            # Extract model URI and register it\n",
    "            model_uri = model_info.model_uri\n",
    "            model_version = mlflow.register_model(model_uri, \"SVMModel\")\n",
    "\n",
    "            print(f\"Model registered as 'SVMModel' with version: {model_version.version}\")\n",
    "\n",
    "    return best_params, best_metrics\n",
    "\n",
    "# Run the search\n",
    "best_params_svm, best_metrics_svm = param_search_svm(msg_train, label_train, msg_val, label_val, pipeline_svm)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nBest Parameters (SVM):\", best_params_svm)\n",
    "print(f\"Final Metrics (SVM):\")\n",
    "for metric, value in best_metrics_svm.items():\n",
    "    print(f\"{metric}: {value * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_NB = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=lambda x: x, preprocessor=None, lowercase=False)),\n",
    "    ('classifier', MultinomialNB())  # Classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/04 21:46:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'NaiveBayesModel' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model registered as 'NaiveBayesModel' with version: 10\n",
      "\n",
      "Best Parameters (NB): (True, 0.1)\n",
      "Final Metrics (NB):\n",
      "Accuracy: 94.26%\n",
      "Precision: 98.85%\n",
      "Recall: 57.72%\n",
      "F1-score: 72.88%\n",
      "AUCPR: 94.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '10' of model 'NaiveBayesModel'.\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "def param_search_nb(msg_train, label_train, msg_val, label_val, pipeline_NB):\n",
    "    param_grid = {\n",
    "        'tfidf__use_idf': [True, False],\n",
    "        'classifier__alpha': [0.1, 0.5, 1.0, 2.0]\n",
    "    }\n",
    "\n",
    "    param_combinations = list(product(*param_grid.values()))\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_metrics = {}\n",
    "\n",
    "    for params in param_combinations:\n",
    "        try:\n",
    "            # Set parameters for the pipeline\n",
    "            pipeline_NB.set_params(\n",
    "                tfidf__use_idf=params[0],\n",
    "                classifier__alpha=params[1]\n",
    "            )\n",
    "            \n",
    "            pipeline_NB.fit(msg_train, label_train)\n",
    "            val_predictions = pipeline_NB.predict(msg_val)\n",
    "            val_probabilities = pipeline_NB.predict_proba(msg_val)[:, 1]\n",
    "\n",
    "            # Compute evaluation metrics\n",
    "            val_accuracy = accuracy_score(label_val, val_predictions)\n",
    "            val_precision = precision_score(label_val, val_predictions, pos_label='spam', zero_division=0)\n",
    "            val_recall = recall_score(label_val, val_predictions, pos_label='spam', zero_division=0)\n",
    "            val_f1 = f1_score(label_val, val_predictions, pos_label='spam', zero_division=0)\n",
    "            val_aucpr = average_precision_score((label_val == 'spam').astype(int), val_probabilities)\n",
    "\n",
    "            # Track best model\n",
    "            if val_f1 > best_score:\n",
    "                best_score = val_f1\n",
    "                best_params = params\n",
    "                best_model = pipeline_NB\n",
    "                best_metrics = {\n",
    "                    \"Accuracy\": val_accuracy,\n",
    "                    \"Precision\": val_precision,\n",
    "                    \"Recall\": val_recall,\n",
    "                    \"F1-score\": val_f1,\n",
    "                    \"AUCPR\": val_aucpr\n",
    "                }\n",
    "        \n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping params {params} due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Log only the best model\n",
    "    if best_model:\n",
    "        with mlflow.start_run(run_name=\"Best_Naive_Bayes\"):\n",
    "            mlflow.log_params({\"use_idf\": best_params[0], \"alpha\": best_params[1]})\n",
    "            mlflow.log_metrics(best_metrics)\n",
    "\n",
    "            # Log best model and get ModelInfo object\n",
    "            model_info = mlflow.sklearn.log_model(best_model, \"naive_bayes_model\")\n",
    "\n",
    "            # Extract model URI and register it\n",
    "            model_uri = model_info.model_uri\n",
    "            model_version = mlflow.register_model(model_uri, \"NaiveBayesModel\")\n",
    "\n",
    "            print(f\"Model registered as 'NaiveBayesModel' with version: {model_version.version}\")\n",
    "\n",
    "    return best_params, best_metrics\n",
    "\n",
    "# Run the search\n",
    "best_params_nb, best_metrics_nb = param_search_nb(msg_train, label_train, msg_val, label_val, pipeline_NB)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nBest Parameters (NB):\", best_params_nb)\n",
    "print(f\"Final Metrics (NB):\")\n",
    "for metric, value in best_metrics_nb.items():\n",
    "    print(f\"{metric}: {value * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
